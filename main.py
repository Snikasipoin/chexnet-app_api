import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from flask import Flask, request, render_template, jsonify
from flask_cors import CORS
from PIL import Image
from werkzeug.utils import secure_filename
import matplotlib.pyplot as plt
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

try:
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è Flask-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...")
    app = Flask(__name__)
    CORS(app, resources={r"/*": {"origins": "*"}})
except Exception as e:
    print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Flask:")
    print(e)
    raise

CORS(app)

UPLOAD_FOLDER = 'static/uploads'
RESULT_FOLDER = 'static/results'
MODEL_PATH = 'model.pth.tar'

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULT_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# OpenRouter OpenAI client
openai_client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load model
model = models.densenet121(pretrained=False)
num_classes = 14
model.classifier = nn.Linear(model.classifier.in_features, num_classes)

try:
    checkpoint = torch.load(MODEL_PATH, map_location=device)
    state_dict = checkpoint.get("state_dict", checkpoint)
    corrected_state_dict = {k.replace("densenet121.", "").replace("classifier.0.", "classifier."): v for k, v in state_dict.items()}
    model.load_state_dict(corrected_state_dict)
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    exit(1)

model.to(device)
model.eval()

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.activations = None
        self.gradients = None
        self.model.eval()
        self.target_layer.register_forward_hook(self.save_activations)
        self.target_layer.register_full_backward_hook(self.save_gradients)

    def save_activations(self, module, input, output):
        self.activations = output

    def save_gradients(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate(self, input_tensor, class_idx=None):
        input_tensor = input_tensor.to(device)
        output = self.model(input_tensor)
        if class_idx is None:
            class_idx = torch.argmax(output, dim=1).item()
        self.model.zero_grad()
        score = output[0, class_idx]
        score.backward()
        gradients = self.gradients.cpu().data.numpy()[0]
        activations = self.activations.cpu().data.numpy()[0]
        weights = np.mean(gradients, axis=(1, 2))
        cam = np.zeros(activations.shape[1:], dtype=np.float32)
        for i, w in enumerate(weights):
            cam += w * activations[i]
        cam = np.maximum(cam, 0)
        cam = cv2.resize(cam, (224, 224))
        cam = cam / np.max(cam)
        return cam, class_idx

def process_image(image_path):
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)

    grad_cam = GradCAM(model, model.features.denseblock4)
    heatmap, pred_class = grad_cam.generate(img_tensor)

    with torch.no_grad():
        output = model(img_tensor)
        probs = torch.sigmoid(output)[0].cpu().numpy()

    img_cv = cv2.imread(image_path)
    img_cv = cv2.resize(img_cv, (224, 224))
    heatmap_img = np.uint8(255 * heatmap)
    heatmap_img = cv2.applyColorMap(heatmap_img, cv2.COLORMAP_JET)
    superimposed_img = heatmap_img * 0.4 + img_cv
    heatmap_path = os.path.join(RESULT_FOLDER, "heatmap.jpg")
    cv2.imwrite(heatmap_path, superimposed_img)

    class_names = [
        "–ù–æ—Ä–º–∞", "–ö–∞—Ä–¥–∏–æ–º–µ–≥–∞–ª–∏—è", "–≠–º—Ñ–∏–∑–µ–º–∞", "–û—Ç–µ–∫", "–ì—Ä—ã–∂–∞", "–ò–Ω—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è",
        "–ú–∞—Å—Å–∞", "–£–∑–µ–ª–æ–∫", "–ê—Ç–µ–ª–µ–∫—Ç–∞–∑", "–ü–Ω–µ–≤–º–æ–Ω–∏—è", "–ü–ª–µ–≤—Ä–∏—Ç", "–ü–Ω–µ–≤–º–æ—Ç–æ—Ä–∞–∫—Å",
        "–§–∏–±—Ä–æ–∑", "–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è"
    ]
    top_probs_idx = np.argsort(probs)[::-1][:5]
    top_probs = probs[top_probs_idx]
    top_labels = [class_names[idx] for idx in top_probs_idx]

    plt.figure(figsize=(10, 5))
    plt.bar(top_labels, top_probs * 100, color='skyblue')
    plt.xlabel('–ö–ª–∞—Å—Å—ã')
    plt.ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)')
    plt.title('–¢–æ–ø-5 –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π')
    plt.xticks(rotation=45)
    plot_path = os.path.join(RESULT_FOLDER, "probs_plot.png")
    plt.savefig(plot_path, bbox_inches='tight')
    plt.close()

    return pred_class, image_path, heatmap_path, plot_path, probs

def interpret_result(pred_class, probs):
    class_names = [
        "–ù–æ—Ä–º–∞", "–ö–∞—Ä–¥–∏–æ–º–µ–≥–∞–ª–∏—è", "–≠–º—Ñ–∏–∑–µ–º–∞", "–û—Ç–µ–∫", "–ì—Ä—ã–∂–∞", "–ò–Ω—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è",
        "–ú–∞—Å—Å–∞", "–£–∑–µ–ª–æ–∫", "–ê—Ç–µ–ª–µ–∫—Ç–∞–∑", "–ü–Ω–µ–≤–º–æ–Ω–∏—è", "–ü–ª–µ–≤—Ä–∏—Ç", "–ü–Ω–µ–≤–º–æ—Ç–æ—Ä–∞–∫—Å",
        "–§–∏–±—Ä–æ–∑", "–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è"
    ]
    top_probs_idx = np.argsort(probs)[::-1][:3]
    prob_str = "\n".join([f"{class_names[idx]}: {probs[idx] * 100:.2f}%" for idx in top_probs_idx])
    max_prob = probs[pred_class]
    if max_prob < 0.5:
        return f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {max_prob * 100:.2f}%)\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:\n{prob_str}"
    return f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_names[pred_class]}\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:\n{prob_str}"

def generate_medical_summary(interpretation: str) -> str:
    try:
        response = openai_client.chat.completions.create(
            model="deepseek/deepseek-chat-v3-0324:free",
            extra_headers={
                "HTTP-Referer": "http://localhost",
                "X-Title": "CheXNet Assistant"
            },
            extra_body={},
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥."},
                {"role": "user", "content": (
                    "–í—ã —Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –ò–ò-–º–æ–¥–µ–ª–∏ –ø–æ —Ä–µ–Ω—Ç–≥–µ–Ω—É –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏. "
                    f"–í–æ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º –∏ –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏:\n{interpretation}\n\n"
                    "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ, –∫–∞–∫ –≤—Ä–∞—á –±—ã –Ω–∞–ø–∏—Å–∞–ª –µ–≥–æ –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–µ. –£–∫–∞–∂–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ç–æ–ª–æ–≥–∏–∏ –∏ —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏."
                )}
            ],
            temperature=0.5,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–∫–ª—é—á–µ–Ω–∏—è –≤—Ä–∞—á–∞: {str(e)}"

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω."}), 400
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)

        pred_class, original_path, heatmap_path, plot_path, probs = process_image(file_path)
        interpretation = interpret_result(pred_class, probs)
        gpt_diagnosis = generate_medical_summary(interpretation)

        base_url = request.url_root.rstrip('/')
        return jsonify({
            "original_url": f"{base_url}/{original_path}",
            "heatmap_url": f"{base_url}/{heatmap_path}",
            "plot_url": f"{base_url}/{plot_path}",
            "interpretation": interpretation,
            "gpt_diagnosis": gpt_diagnosis
        })
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"}), 500

if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=int(os.environ.get('PORT', 5000)))
